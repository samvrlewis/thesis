\chapter{Project outline}

From the section \ref{impacts}, it was determined that a classifier to measure cattle feed efficiency should be built that can:

\begin{itemize}
\item Run in real time on a sensor node
\item Make classifications from sensor data
\item Count the number of chews individual cattle make
\end{itemize}

However, to do this in general, for any animal phenotypic trait measurement problem that can be observed through sensor data the following process needs to be undertaken. 

\begin{enumerate}
\item Identify the trait wanting to be captured (for feed efficiency, number of chews).

\item Experimentally record sensor data while the livestock are in their commercial environment. 

\item Curate data so that it can easily be queried and searched through

\item Annotate data, classifying when the animal is exhibiting the particular trait of interest and when it is not

\item Using the previously annotated data to design an algorithm to classify the trait of interest

\item Testing the performance of the designed algorithm against other annotated data

\item Implementation of the algorithm on the embedded hardware to run in the field
\end{enumerate}

The main goal of the thesis is to therefore produce a framework that facilitates the process of rapidly developing a classification algorithm using experimentally recorded data. This is contextualised through the cattle feed efficiency example but, as previously stated, the procedure will be similar for any other phenotype that can be observed through sensor data.

\section{Classifier Development Framework }

A block diagram of the framework needed to develop a classifier to classify phenotypic information from time-series sensor data (such as the data from the experiments outlined in section~\ref{sec:prior work}) is shown in figure \ref{frameworkblock}

\missingfigure{Block diagram of whole system}

The purpose for each block of the framework is discussed in the next sections.

\todo{this probably needs to be more general - less about cows}

\subsection{Data Curation/Extraction}
As outlined in  section~\ref{sec:prior work}, a number of experiments with sensors attached to cattle have been performed. This data will be used to both design a classifier and verify the performance of it. 

The eartag stores data in the Tagged Data Format (TDF - see section~\ref{TDF} for more details) on SD storage. Because of the large amount of sensor data collected experimentally, it would be convenient to curate the data so it is easier to access. Presently, the data is stored in a binary format; the first task of the project will be extracting and then converting the data into the Hierarchical Data Format (HDF). HDF is designed for use with large datasets of numerical data so it is perfect for the task.

Once the data has been converted into the HDF format it can be accessed through the RESTful Application Programming Interface (API). This allows for simple remote data access via a web address. The RESTful API also allows for data querying and simple statistics which will simplify the process of extracting data.

As soon as the data is able to be accessed through via the RESTful interface, the next step will be to investigate the data to find behavioural events for classification. This will involve finding when there is overlap between sensor data recordings and video so that the sensor data can be annotated with behavioural information.

\subsection{Data Annotation}

Creating training and test sets is important for the design of a automated classifier. These sets consist of sets of input data and correct classifications for that input data. In this case, the sets will consist of chewing/not chewing events with corresponding sensor data. 

To create the sets, the videos of the cattle will be viewed and events will be found. The recorded audio will also be used to precisely match the event start and end times.  

To assist with this a data annotation interface  will be built. This should take the form of an application that allows sensor data to be loaded in and displayed so that a user can manually annotate sections of the data as a chew/not chew event. Sections of the audio data should also be able to be played from this interface. 

Ideally annotations should be stored in a database like system, along with the sensor data. This would simplify the process of interfacing with the annotations and extracting annotations and corresponding data. 

For a good classifier, it is important to create sets that not only have positive events (eg. chewing) but also negative events (eg. any event where the animal is not chewing).

\subsection{Classifier Design and Verification} 

Once some of the data in the system has been annotated, a classifier will begin to be designed. Research will be performed to determine the best underlying platform for the classifer to run on. 

To allow the classifier to be designed using the already annotated data, the classifier should be able to connect directly to the annotation data and sensor data stores. For this reason, rather than develop the classifier directly for the sensor node that it will eventually run on, the classifier will be prototyped in a higher level programming language. This will allow quicker prototyping for the classifier and will be easier to verify.

When the classifier has been designed, its accuracy will need to be verified. This will involve estimating the accuracy of the classifier by using it with the test set that has already been created. Care should be taken not to test the classifier using data that was used to train it. 